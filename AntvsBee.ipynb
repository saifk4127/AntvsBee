{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b73d0ea",
   "metadata": {},
   "source": [
    "# Ant versus Bee Classification using Pre-trained ResNet-18 Convolutional Neural Network Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19301d6d",
   "metadata": {},
   "source": [
    "### Objective : Practice using pre-trained neural networks to extract domain-specific features for new tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "1d91a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x241829b9460>"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function, division          ##https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ef4cc",
   "metadata": {},
   "source": [
    "# Read the pytorch tutorial to use a pre-trained “ConvNet as fixed feature extractor” \n",
    "fromhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html and you can ignore “finetuning theConvNet”. Test this code out to see if it runs properly in your environment after eliminating code blocks thatyou do not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "6c4ebe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##                            https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "## this code is taken from link rovided in assignment\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "data_dir =\"C:/Users/alnea/OneDrive/Desktop/hymenoptera_data\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b8ab2",
   "metadata": {},
   "source": [
    "# #Write a function that outputs ResNet18 features for a given input image. \n",
    "Extract features for training images(in image_datasets['train']). You should get an Nx512 dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "e12eacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img='C:/Users/alnea/OneDrive/Desktop/hymenoptera_data'\n",
    "# Define function to get features, shape of features\n",
    "def resnet_18_feature_extraction(path):\n",
    "        ## defining model\n",
    "        model_resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "        ## Obtaining number of feature from last connected layer\n",
    "        num_ftrs = model_resnet18.fc.in_features \n",
    "\n",
    "        # replacing last connected layer as identity\n",
    "        model_resnet18.fc = torch.nn.Identity()\n",
    "\n",
    "        # Setting model to evaluation mode to get reliable outputs\n",
    "        model_resnet18.eval()\n",
    "        ## these lines taken from link mentioned in question\n",
    "        transform = transforms.Compose([                      ##  https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        # Load the training dataset\n",
    "        dataset = datasets.ImageFolder(path, transform=transform)    ##https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "        # data loader                         https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)  ##https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "\n",
    "        # Extracting features for each image in the training dataset\n",
    "        features_extracted = []\n",
    "        # disabling the gradient to reduce memory consumption\n",
    "        with torch.no_grad():                               ##https://pytorch.org/docs/stable/generated/torch.no_grad.html\n",
    "            for images,labels in dataloader:\n",
    "                extraction= model_resnet18(images)\n",
    "                features_extracted.append(extraction)\n",
    "\n",
    "        # Concatenating tensor of features & converting to numpy array\n",
    "        features_extracted = torch.cat(features_extracted, dim=0).numpy()   ##https://pytorch.org/docs/stable/generated/torch.cat.html\n",
    "        return features_extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "1d8182f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 512)"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=resnet_18_feature_extraction (path_img)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "d5a19932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting train and test data from the features extracted and target from image_dataset\n",
    "x_train=features[0:244]\n",
    "x_test=features[244:397]\n",
    "y_train=np.array(image_datasets['train'].targets)\n",
    "y_test=np.array(image_datasets['val'].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "fd7eb07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244,)"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b547a",
   "metadata": {},
   "source": [
    "## Compare L2 regularized logistic regression, RBF kernel SVM (do grid search on kernel width andregularization), and random forest (do grid search on max depth and number of trees). \n",
    "Test the final modelon test data and show the results -- accuracy and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b184a",
   "metadata": {},
   "source": [
    "# a) L2 regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "9ceeec4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_hyperparameters: {'C': 0.001}\n",
      "best_f1_score: 0.9628893818396923\n",
      "f1_score: 0.9634146341463414\n",
      "Accuracy: 0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "# Importing LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model= LogisticRegression()                               ## https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# Making a hyperparameter dictionary \n",
    "hyperparameter_grid={'C': [0.001,0.01,0.1,1,10]}\n",
    "#Calling gridsearch cv for hyperparameter tuning\n",
    "grid_search_cv = GridSearchCV(estimator=LR_model,param_grid=hyperparameter_grid,cv=5,scoring='f1')\n",
    "#fitting gridsearch sv on train data\n",
    "grid_search_cv.fit(x_train, y_train)\n",
    "#printing best hyperparameters\n",
    "print('best_hyperparameters:',grid_search_cv.best_params_)\n",
    "#printing best f1 score in the CVs\n",
    "print('best_f1_score:',grid_search_cv.best_score_)\n",
    "\n",
    "# Predicting the classification on the basis of test data\n",
    "y_pred=grid_search_cv.predict(x_test)\n",
    "\n",
    "# Getting f1 score\n",
    "f1=f1_score(y_test,y_pred)\n",
    "\n",
    "# Getting accuracy\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "\n",
    "#printing F1 score & Accuracy\n",
    "print('f1_score:',f1)\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5788f",
   "metadata": {},
   "source": [
    "# b) RBF kernel SVM (do grid search on kernel width andregularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "9c00f248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_hyperparameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "best_f1_score: 0.936118100524206\n",
      "f1_score: 0.9506172839506173\n",
      "Accuracy: 0.9477124183006536\n"
     ]
    }
   ],
   "source": [
    "# Making a hyperparameter dictionary \n",
    "hyperparameter_grid = {'C': [0.001,0.01,0.1,1,10],'kernel': ['rbf'],'gamma': [0.01,0.1,1,10,100],'class_weight':['balanced']} \n",
    "#Calling gridsearch cv for hyperparameter tuning\n",
    "grid_search_cv = GridSearchCV(estimator=SVC(),param_grid=hyperparameter_grid,cv=5,scoring='f1')\n",
    "\n",
    "#fitting gridsearch sv on train data\n",
    "grid_search_cv.fit(x_train, y_train)\n",
    "\n",
    "#printing best hyperparameters\n",
    "print('best_hyperparameters:',grid_search_cv.best_params_)\n",
    "#printing best f1 score in the CVs\n",
    "print('best_f1_score:',grid_search_cv.best_score_)\n",
    "\n",
    "# Predicting the classification on the basis of test data\n",
    "y_pred=grid_search_cv.predict(x_test)\n",
    "\n",
    "# Getting f1 score\n",
    "f1=f1_score(y_test,y_pred)\n",
    "\n",
    "# Getting accuracy\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "\n",
    "#printing F1 score & Accuracy\n",
    "print('f1_score:',f1)\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59c99f",
   "metadata": {},
   "source": [
    "# c) Random forest (do grid search on max depth and number of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "87c0770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_hyperparameters: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "best_f1_score: 0.9543608114276807\n",
      "f1_score: 0.9512195121951219\n",
      "Accuracy: 0.9477124183006536\n"
     ]
    }
   ],
   "source": [
    "# Making a hyperparameter dictionary \n",
    "hyperparameter_grid={'max_features':['sqrt','log2'],'n_estimators':[100,150,200,250],'class_weight':['balanced']}   #https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "## assigning RandomForestClassifier() model(estimator)\n",
    "model= RandomForestClassifier(random_state=0)\n",
    "#Calling gridsearch cv for hyperparameter tuning\n",
    "grid_search_cv=GridSearchCV(estimator=model,param_grid=hyperparameter_grid,cv=5,scoring='f1')\n",
    "#fitting gridsearch cv on train data\n",
    "grid_search_cv.fit(x_train, y_train)\n",
    "\n",
    "#printing best hyperparameters\n",
    "print('best_hyperparameters:',grid_search_cv.best_params_)\n",
    "#printing best f1 score in the CVs\n",
    "print('best_f1_score:',grid_search_cv.best_score_)\n",
    "\n",
    "# Predicting the classification on the basis of test data\n",
    "y_pred=grid_search_cv.predict(x_test)\n",
    "\n",
    "# Getting f1 score\n",
    "f1=f1_score(y_test,y_pred)\n",
    "\n",
    "# Getting accuracy\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "\n",
    "#printing F1 score & Accuracy\n",
    "print('f1_score:',f1)\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce819558",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "\n",
    "\n",
    "### ----------------Logistic Regression-------RBF---------------------------------------Randomforest\n",
    "\n",
    "###### F1_score-----0.9634146341463414--------------0.9506172839506173------------------------------0.9512195121951219              \n",
    "###### Accuracy------0.9607843137254902-------------0.9477124183006536----------------------------- 0.9477124183006536\n",
    "\n",
    "### All three models are classifing on test data well and almost close accuracy & f1 score, But Linear Regression is giving slightly higher accuracy and f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fd600",
   "metadata": {},
   "source": [
    "# 12). Summarize your findings and write your references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a680076",
   "metadata": {},
   "source": [
    "Findings\n",
    "1) How to do exploratory data analysis by variance of features, corelations between features,null value imputation and elimination\n",
    "\n",
    "2) The Model gives high score on train data but low performance on test data, it means model are not that much generalizable.\n",
    "\n",
    "3) How the pretrained resnet18 model can be used for feature extraction\n",
    "\n",
    "4) It is importanat to give equal weight to all classes otherwise we get scores influenced by imbalance.\n",
    "\n",
    "5) The neural network takes more time for hyperparameter tuning almost around half an hour\n",
    "\n",
    "6) It is necessary to convert last layer of resnet18 as identity to get features from it.\n",
    "\n",
    "7) for the execution of code where grad is not required, no grad should be execute to avoid memory consumption\n",
    "\n",
    "8) Gridsearch CV does multiple cross validation which helps to get hyperparameter to generalize the model.\n",
    "\n",
    "9) In Multiclass classification using linear SVM i got same score for recursive feature elimination model and the feature eliminated manually.\n",
    "\n",
    "10) The model were performing good on the extracted features from resnet18 feature extractor.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##References \n",
    "I have mentioned links next to code line in code block\n",
    "1) Andrew ng coursera neural network videos\n",
    "\n",
    "2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
